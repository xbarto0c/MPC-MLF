{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3kTQRL57tDfVp2w1lhOo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xbarto0c/MPC-MLF/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QQMThjwKKGZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe4d11a-7843-45c2-fb23-d7d4653e9043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 06:41:46--  https://www.gutenberg.org/files/5200/5200-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142017 (139K) [text/plain]\n",
            "Saving to: ‘kafka_Metamorphosis.txt’\n",
            "\n",
            "\rkafka_Metamorphosis   0%[                    ]       0  --.-KB/s               \rkafka_Metamorphosis 100%[===================>] 138.69K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-04-06 06:41:46 (3.09 MB/s) - ‘kafka_Metamorphosis.txt’ saved [142017/142017]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, LSTM\n",
        "from keras.optimizers import RMSprop # RootMeanSquare Error\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "!wget -O kafka_Metamorphosis.txt https://www.gutenberg.org/files/5200/5200-0.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('kafka_Metamorphosis.txt', 'r').read().lower();\n",
        "print('text length: ',len(text));\n",
        "print(text[:2020]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z6BvOnlLfa_",
        "outputId": "23323b3b-81ea-47ef-f5ce-57686bb8b789"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text length:  138408\n",
            "﻿the project gutenberg ebook of metamorphosis, by franz kafka\n",
            "\n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the project gutenberg license included with this ebook or online at\n",
            "www.gutenberg.org. if you are not located in the united states, you\n",
            "will have to check the laws of the country where you are located before\n",
            "using this ebook.\n",
            "\n",
            "** this is a copyrighted project gutenberg ebook, details below **\n",
            "**     please follow the copyright guidelines in this file.     **\n",
            "\n",
            "title: metamorphosis\n",
            "\n",
            "author: franz kafka\n",
            "\n",
            "translator: david wyllie\n",
            "\n",
            "release date: may 13, 2002 [ebook #5200]\n",
            "[most recently updated: may 20, 2012]\n",
            "\n",
            "language: english\n",
            "\n",
            "character set encoding: utf-8\n",
            "\n",
            "copyright (c) 2002 by david wyllie.\n",
            "\n",
            "*** start of the project gutenberg ebook metamorphosis ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "metamorphosis\n",
            "\n",
            "by franz kafka\n",
            "\n",
            "translated by david wyllie\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "i\n",
            "\n",
            "\n",
            "one morning, when gregor samsa woke from troubled dreams, he found\n",
            "himself transformed in his bed into a horrible vermin. he lay on his\n",
            "armour-like back, and if he lifted his head a little he could see his\n",
            "brown belly, slightly domed and divided by arches into stiff sections.\n",
            "the bedding was hardly able to cover it and seemed ready to slide off\n",
            "any moment. his many legs, pitifully thin compared with the size of the\n",
            "rest of him, waved about helplessly as he looked.\n",
            "\n",
            "“what’s happened to me?” he thought. it wasn’t a dream. his room, a\n",
            "proper human room although a little too small, lay peacefully between\n",
            "its four familiar walls. a collection of textile samples lay spread out\n",
            "on the table—samsa was a travelling salesman—and above it there hung a\n",
            "picture that he had recently cut out of an illustrated magazine and\n",
            "housed in a nice, gilded frame. it showed a lady fitted out with a fur\n",
            "hat and fur boa who sat upright, raising a heavy fur muff that covered\n",
            "the whole of her lower arm towards the viewer.\n",
            "\n",
            "greg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)));\n",
        "print('Num of chars: ', len(chars));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTKSnpg8MzDu",
        "outputId": "147a214c-c189-4ae4-b639-975842a8f165"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of chars:  62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars));\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars));"
      ],
      "metadata": {
        "id": "RlL0VFENNKzX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dělení textu na části po 40 znacích -> učení se po frázích\n",
        "maxlen = 40;\n",
        "step = 3; # Krokování částí\n",
        "sentences = [];\n",
        "next_chars = []; # Další predikované znaky\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i:i + maxlen]);\n",
        "  next_chars.append(text[i + maxlen]);\n",
        "\n",
        "print('nb sentences: ', len(sentences));\n",
        "print(sentences[:3]);\n",
        "print(next_chars[:3]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP4J3-oPNi38",
        "outputId": "2c55bf61-3970-4674-f80f-439f6c01b277"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sentences:  46123\n",
            "['\\ufeffthe project gutenberg ebook of metamorp', 'e project gutenberg ebook of metamorphos', 'roject gutenberg ebook of metamorphosis,']\n",
            "['h', 'i', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encoding\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool);\n",
        "y = np.zeros((len(sentences), len(chars)), dtype = np.bool);\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1;\n",
        "    y[i, char_indices[next_chars[i]]] = 1;\n",
        "print(x[:3]);\n",
        "print(y[:3]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKhFGoKOOyTZ",
        "outputId": "a27b25dc-5919-480b-ee67-317d7120a9c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e1d844c42748>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool);\n",
            "<ipython-input-32-e1d844c42748>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype = np.bool);\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False  True False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential();\n",
        "model.add(LSTM(254, input_shape = (maxlen, len(chars))));\n",
        "model.add(Dense(10*len(chars)));\n",
        "model.add(Dense(len(chars)));\n",
        "model.add(Activation('softmax'));"
      ],
      "metadata": {
        "id": "K7ZCHfR5P8D2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(learning_rate = 0.01));"
      ],
      "metadata": {
        "id": "jWa4lQKdQqvZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size = 128, epochs = 30);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAKhyMrSRp-R",
        "outputId": "bb1f87ad-eab5-4536-edfa-3929abe6f8db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "361/361 [==============================] - 4s 8ms/step - loss: 4.1816\n",
            "Epoch 2/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 2.0216\n",
            "Epoch 3/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.7609\n",
            "Epoch 4/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.5985\n",
            "Epoch 5/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.4789\n",
            "Epoch 6/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.3714\n",
            "Epoch 7/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.2833\n",
            "Epoch 8/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.1951\n",
            "Epoch 9/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 1.1047\n",
            "Epoch 10/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 1.0263\n",
            "Epoch 11/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.9553\n",
            "Epoch 12/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.8891\n",
            "Epoch 13/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.8241\n",
            "Epoch 14/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.7736\n",
            "Epoch 15/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.7237\n",
            "Epoch 16/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6806\n",
            "Epoch 17/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.6353\n",
            "Epoch 18/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.6063\n",
            "Epoch 19/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.5670\n",
            "Epoch 20/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.5397\n",
            "Epoch 21/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.5118\n",
            "Epoch 22/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.4912\n",
            "Epoch 23/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.4678\n",
            "Epoch 24/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.4442\n",
            "Epoch 25/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.4336\n",
            "Epoch 26/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.4099\n",
            "Epoch 27/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3936\n",
            "Epoch 28/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3782\n",
            "Epoch 29/30\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.3704\n",
            "Epoch 30/30\n",
            "361/361 [==============================] - 3s 8ms/step - loss: 0.3569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vzorkování indexu z pole pravděpodobností\n",
        "def sample(preds, temperature = 0.1):\n",
        "  preds = np.asarray(preds).astype('float64');\n",
        "  preds = np.log(preds) / temperature;\n",
        "  exp_preds = np.exp(preds);\n",
        "  preds = exp_preds / np.sum(exp_preds);\n",
        "  probas = np.random.multinomial(1, preds, 1);\n",
        "  return np.argmax(probas);\n",
        "# Vybere pomocí pomocné funkce znak a sestaví větu\n",
        "def generate_text(sentence, length, diversity):\n",
        "  generated = '';\n",
        "  generated += sentence;\n",
        "  for i in range(length):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)));\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indices[char]] = 1.;\n",
        "    \n",
        "    preds = model.predict(x_pred, verbose = 0)[0];\n",
        "    next_index = sample(preds, diversity);\n",
        "    next_char = indices_char[next_index];\n",
        "\n",
        "    generated += next_char;\n",
        "    sentence = sentence[1:] + next_char;\n",
        "  return generated;"
      ],
      "metadata": {
        "id": "f_ekIrPDYE__"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"save the world from devastation, reunite\"; # The imput to be completed, MUST be 40 chars long\n",
        "       \n",
        "sentence = text[0: maxlen];\n",
        "\n",
        "print(generate_text(sentence, 30, 0.2));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0FMD2xaG6P",
        "outputId": "544ad079-d828-4f4d-bd8b-6337384987fb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save the world from devastation, reunited states complaintudelare must\n"
          ]
        }
      ]
    }
  ]
}